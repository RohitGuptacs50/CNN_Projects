# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LavWkLK37lURS6J-qTq1NXhTROfBm1nc
"""

!unzip "/content/drive/MyDrive/Colab Notebooks/CatsVsDogs/Small.zip" -d "/content/drive/MyDrive/Colab Notebooks/CatsVsDogs/Small Test"

import glob
import  numpy as np
import os
import shutil
from distutils.dir_util import copy_tree
from PIL import Image
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img

np.random.seed(42)

IMG_DIM = (150, 150)

train_folder = glob.glob('/content/drive/MyDrive/Colab Notebooks/CatsVsDogs/Small Test/Small/train/*')
train_images = [img_to_array(load_img(image, target_size = IMG_DIM)) for image in train_folder]
train_images = np.array(train_images)
train_labels = [fl.split('/')[-1].split(' ')[0].strip() for fl in train_folder]


print('Train dataset shape:', train_images.shape)

validation_folder = glob.glob('/content/drive/MyDrive/Colab Notebooks/CatsVsDogs/Small Test/Small/eval/*')
validation_images = [img_to_array(load_img(image, target_size = IMG_DIM)) for image in validation_folder]
validation_images = np.array(validation_images)
validation_labels = [fl.split('/')[-1].split(' ')[0].strip() for fl in validation_files]

print('Validation dataset shape: ', validation_images.shape)

train_images_scaled = train_images.astype('float32')
validation_images_scaled = validation_images.astype('float32')
train_images_scaled /= 255
validation_images_scaled /= 255

print(train_images[0].shape)
array_to_img(train_images[0])

print(validation_labels[0])
print()
print(train_labels[0])

batch_size = 30
numb_classes = 2
epochs = 30
input_shape = (150, 150, 3)

from sklearn.preprocessing import LabelEncoder

LE = LabelEncoder()
LE.fit(train_labels)
train_LE = LE.transform(train_labels)
validation_LE = LE.transform(validation_labels)

print(train_labels[1495:1505], train_LE[1495:1505])

train_datagenerator = ImageDataGenerator(rescale=1./255, zoom_range=0.3, rotation_range=50,
                                   height_shift_range=0.2, width_shift_range=0.2, 
                                   shear_range=0.2,fill_mode='nearest', horizontal_flip=True
                                   )

val_datagenerator = ImageDataGenerator(rescale=1./255)

image_id = 2510
dog_generator = train_datagenerator.flow(train_images[image_id:image_id + 1], train_labels[image_id:image_id + 1],
                                   batch_size=7)
dog = [next(dog_generator) for j in range(0, 5)]
fig, ax = plt.subplots(1, 5, figsize=(16, 6))
print('Labels:', [targ[1][0] for targ in dog])
l = [ax[j].imshow(dog[j][0][0]) for j in range(0, 5)]

image_id = 1001
cat_generator = train_datagen.flow(train_imgs[image_id:image_id + 1], train_labels[image_id:image_id + 1],
                                   batch_size=1)
cat = [next(cat_generator) for j in range(0, 5)]
fig, ax = plt.subplots(1, 5, figsize=(15, 6))
print('Labels:', [targ[1][0] for targ in cat])
l = [ax[j].imshow(cat[j][0][0]) for j in range(0, 5)]

train_generator = train_datagenerator.flow(train_images, train_LE, batch_size=30)
val_generator = val_datagenerator.flow(validation_images, validation_LE, batch_size = 20)
input_shape = (150, 150, 3)

from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from keras.models import Sequential
from keras import optimizers

model=Sequential()

model.add(Conv2D(16, kernel_size=(3, 3), activation='relu',
                 input_shape = input_shape))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))


model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy', 
              optimizer=optimizers.RMSprop(lr=1e-4),
              metrics=['accuracy'])

history = model.fit_generator(train_generator, steps_per_epoch = 100, epochs=100,
                              validation_data=val_generator, validation_steps=50,
                              verbose=1)

f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
t = f.suptitle('CNN with Image Augmentation Performance', fontsize=12)
f.subplots_adjust(top=0.901, wspace = 0.35)

epochs_list = list(range(1, 101))
ax1.plot(epochs_list, history.history['accuracy'], label = 'Train Accuracy')
ax1.plot(epochs_list, history.history['val_accuracy'], label='Validation_Accuracy')
ax1.set_xticks(np.arange(0, 101, 5))
ax1.set_ylabel('Accuracy Value')
ax1.set_xlabel('Epoch')
ax1.set_title('Accuracy')
la = ax1.legend(loc = "best")

ax2.plot(epochs_list, history.history['loss'], label='Train Loss')
ax2.plot(epochs_list, history.history['val_loss'], label='Validation Loss')
ax2.set_xticks(np.arange(0, 101, 5))
ax2.set_ylabel('Loss Value')
ax2.set_xlabel('Epoch')
ax2.set_title('Loss')
l2 = ax2.legend(loc="best")

model.save('cats_dogs_cnn_img_aug.h5')

from keras.applications import vgg16
from keras.models import Model
import keras

vgg_net = vgg16.VGG16(include_top=False, weights='imagenet',
                  input_shape = input_shape)

output = vgg_net.layers[-1].output
output = keras.layers.Flatten()(output)
vgg16_model = Model(vgg_net.input, output)

vgg16_model.trainable = False
for layer in vgg16_model.layers:
  layer.trainable = False


import pandas as pd
pd.set_option('max_colwidth', -1)
layers = [(layer, layer.name, layer.trainable) for layer in vgg16_model.layers]
pd.DataFrame(layers, columns=['type', 'name', 'layer_to_train'])

bottleneck_features = vgg_net.predict(train_images_scaled[0:1])
print(bottleneck_features.shape)
plt.imshow(bottleneck_features[0][:,:,0])

def get_bottleneck_features(model, input_images):
  features = model.predict(input_images, verbose=0)
  return features

train_features_vgg_net = get_bottleneck_features(vgg16_model, train_images_scaled)
validation_features_vgg_net = get_bottleneck_features(vgg16_model, validation_images_scaled)

print('Train Bottleneck Features:', train_features_vgg_net.shape,
      '\tValidation Bottleneck Features: ', validation_features_vgg_net.shape)

from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout,InputLayer
from keras.models import Sequential
from keras import optimizers

input_shape = vgg16_model.output_shape[1]

model = Sequential()
model.add(InputLayer(input_shape=(input_shape,)))
model.add(Dense(512, activation='relu', input_dim=input_shape))
model.add(Dropout(0.3))

model.add(Dense(512, activation='relu'))
model.add(Dropout(0.3))

model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4),
              metrics=['accuracy'])

model.summary()

history = model.fit(x=train_features_vgg_net, y=train_LE,
                    validation_data=(validation_features_vgg_net, validation_LE),
                    batch_size = batch_size,
                    epochs = epochs,
                    verbose=1)

f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
t = f.suptitle('CNN with Image Augmentation Performance', fontsize=12)
f.subplots_adjust(top=0.901, wspace = 0.35)

epoch_list = list(range(1, 31))
ax1.plot(epoch_list, history.history['accuracy'], label = 'Train Accuracy')
ax1.plot(epoch_list, history.history['val_accuracy'], label='Validation_Accuracy')
ax1.set_xticks(np.arange(0, 31, 2))
ax1.set_ylabel('Accuracy Value')
ax1.set_xlabel('Epoch')
ax1.set_title('Accuracy')
la = ax1.legend(loc = "best")

ax2.plot(epoch_list, history.history['loss'], label='Train Loss')
ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')
ax2.set_xticks(np.arange(0, 31, 2))
ax2.set_ylabel('Loss Value')
ax2.set_xlabel('Epoch')
ax2.set_title('Loss')
l2 = ax2.legend(loc="best")

model.save('cats_dogs_tlearn_vgg16_basic_cnn.h5')

train_datagenerator = ImageDataGenerator(rescale=1./255, zoom_range=0.3, rotation_range=50,
                                   height_shift_range=0.2, width_shift_range=0.2, 
                                   shear_range=0.2,fill_mode='nearest', horizontal_flip=True,
                                   )
validation_datagenerator = ImageDataGenerator(rescale=1./255)

train_generator = train_datagenerator.flow(train_images, train_LE, batch_size=30)
validation_generator = validation_datagenerator.flow(validation_images, validation_LE, batch_size=20)

from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer
from keras.models import Sequential
from keras import optimizers

model = Sequential()
model.add(vgg16_model)
model.add(Dense(512, activation='relu', input_dim=input_shape))
model.add(Dropout(0.3))

model.add(Dense(512, activation='relu'))
model.add(Dropout(0.3))

model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy',
              optimizer=optimizers.RMSprop(lr=2e-5),
              metrics=['accuracy'])

from keras.callbacks import ModelCheckpoint

filepath = '/content/drive/MyDrive/Colab Notebooks/CatsVsDogs/Saved_hdf5 files/weights-{epoch:02d}-{val_accuracy:.3f}.hdf5'

checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy',
                             verbose=1, mode='max')
callbacks_list = [checkpoint]

history = model.fit_generator(train_generator, steps_per_epoch=100, epochs=100,
                              validation_data=validation_generator, validation_steps=50,
                              verbose=1, callbacks = callbacks_list)

from keras.models import load_model

model = load_model("/content/drive/MyDrive/Colab Notebooks/CatsVsDogs/Saved_hdf5 files/weights-01-0.803.hdf5")

history = model.fit_generator(train_generator, steps_per_epoch=100, epochs=100,
                              validation_data=validation_generator, validation_steps=50,
                              verbose=1, callbacks = callbacks_list, initial_epoch = 1)

from keras.models import load_model

model = load_model("/content/drive/MyDrive/Colab Notebooks/CatsVsDogs/Saved_hdf5 files/weights-48-0.884.hdf5")

history = model.fit_generator(train_generator, steps_per_epoch=100, epochs=100,
                              validation_data=validation_generator, validation_steps=50,
                              verbose=1, callbacks = callbacks_list, initial_epoch = 48)

from keras.models import load_model

model = load_model("/content/drive/MyDrive/Colab Notebooks/CatsVsDogs/Saved_hdf5 files/weights-55-0.901.hdf5")

history = model.fit_generator(train_generator, steps_per_epoch=100, epochs=100,
                              validation_data=validation_generator, validation_steps=50,
                              verbose=1, callbacks = callbacks_list, initial_epoch = 55)

from keras.models import load_model

model = load_model("/content/drive/MyDrive/Colab Notebooks/CatsVsDogs/Saved_hdf5 files/weights-68-0.895.hdf5")

history = model.fit_generator(train_generator, steps_per_epoch=100, epochs=100,
                              validation_data=validation_generator, validation_steps=50,
                              verbose=1, callbacks = callbacks_list, initial_epoch = 68)

from keras.models import load_model

model = load_model("/content/drive/MyDrive/Colab Notebooks/CatsVsDogs/Saved_hdf5 files/weights-96-0.900.hdf5")

history = model.fit_generator(train_generator, steps_per_epoch=100, epochs=100,
                              validation_data=validation_generator, validation_steps=50,
                              verbose=1, callbacks = callbacks_list, initial_epoch = 96)

model.save('cats_dogs_tlearn_vgg16_img_aug_cnn.h5')

f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
t = f.suptitle('CNN with Image Augmentation Performance', fontsize=12)
f.subplots_adjust(top=0.901, wspace = 0.35)

epoch_list = list(range(1, 101))
ax1.plot(epoch_list, history.history['accuracy'], label = 'Train Accuracy')
ax1.plot(epoch_list, history.history['val_accuracy'], label='Validation_Accuracy')
ax1.set_xticks(np.arange(0, 101, 5))
ax1.set_ylabel('Accuracy Value')
ax1.set_xlabel('Epoch')
ax1.set_title('Accuracy')
la = ax1.legend(loc = "best")

ax2.plot(epoch_list, history.history['loss'], label='Train Loss')
ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')
ax2.set_xticks(np.arange(0, 101, 2))
ax2.set_ylabel('Loss Value')
ax2.set_xlabel('Epoch')
ax2.set_title('Loss')
l2 = ax2.legend(loc="best")

input_shape = (150, 150, 3)
vgg_net = vgg16.VGG16(include_top=False, weights='imagenet',
                    input_shape = input_shape)

output = vgg_net.layers[-1].output
output = keras.layers.Flatten()(output)
vgg16_model = Model(vgg_net.input, output)

vgg16_model.trainable = True

set_trainable = False
for layer in vgg16_model.layers:
    if layer.name in ['block5_conv1', 'block4_conv1']:
      set_trainable = True
    if set_trainable:
      layer.trainable = True
    else:
      layer.trainable = False

model = Sequential()
model.add(vgg16_model)
model.add(Dense(512, activation='relu', input_dim=input_shape))
model.add(Dropout(0.3))
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(1, activation='sigmoid'))
  

layers = [(layer, layer.name, layer.trainable) for layer in vgg16_model.layers]
pd.DataFrame(layers, columns=['type', 'name', 'layer_to_train'])

train_datagenerator = ImageDataGenerator(rescale=1./255, zoom_range=0.3, 
                                   rotation_range=50, height_shift_range=0.2, width_shift_range=0.2,
                                    shear_range=0.2,fill_mode='nearest',
                                   horizontal_flip = True )
val_datagenerator = ImageDataGenerator(rescale=1./255)
train_generator = train_datagenerator.flow(train_images, train_LE, batch_size=30)
val_generator = val_datagenerator.flow(validation_images, validation_LE, batch_size=20)

import os
import pprint # for pretty printing our device statistics

if 'COLAB_TPU_ADDR' not in os.environ:
    print('ERROR: Not connected to a TPU runtime')
else:
    tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']
    print ('TPU address: ', tpu_address)

    with tf.compat.v1.Session(tpu_address) as session:
      devices = session.list_devices()

    print('TPU devices:')
    pprint.pprint(devices)

tf.config.experimental_connect_to_host('grpc://' + os.environ['COLAB_TPU_ADDR'])
resolver = tf.distribute.cluster_resolver.TPUClusterResolver('grpc://' + os.environ['COLAB_TPU_ADDR'])
tf.tpu.experimental.initialize_tpu_system(resolver)
strategy = tf.distribute.experimental.TPUStrategy(resolver)

from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer
from keras.models import Sequential
from keras import optimizers

model = create_model()
model.compile(loss='binary_crossentropy',
                optimizer=optimizers.RMSprop(lr=1e-5),
                metrics=['accuracy']
                )
model.summary()

history = model.fit_generator(train_generator, steps_per_epoch=100, epochs=100,
                              validation_data=validation_generator, validation_steps=50, 
                              verbose=1)



"""Evaluating the Deep Learning Models on Test Data"""

import glob
import numpy as np
import matplotlib.pyplot as plt
from keras.preprocessing.image import load_img, img_to_array, array_to_img
from keras.models import load_model

from google.colab import files
source = list(files.upload().values())[0]
open('/content/drive/MyDrive/Colab Notebooks/CatsVsDogs/model_evaluation_utils.py','wb').write(source)
import model_evaluation_utils

import model_evaluation_utils as meu

# load saved models
basic_cnn = load_model('/content/drive/MyDrive/Colab Notebooks/CatsVsDogs/cats_dogs_basic_cnn.h5')
img_aug_cnn = load_model('/content/drive/MyDrive/Colab Notebooks/CatsVsDogs/cats_dogs_cnn_img_aug.h5')
t1_cnn = load_model('/content/drive/MyDrive/Colab Notebooks/CatsVsDogs/cats_dogs_tlearn_vgg16_basic_cnn.h5')
t1_img_aug_cnn = load_model('/content/drive/MyDrive/Colab Notebooks/CatsVsDogs/cats_dogs_tlearn_vgg16_img_aug_cnn.h5')

# load other configurations
IMG_DIM = (150, 150)
input_shape = (150, 150, 3)
num2class_label_transformer = lambda l: ['cat' if x == 0 else 'dog' for x in l]
class2num_label_transformer = lambda l: [0 if x == 'cat' else 1 for x in l]

# load vgg model for bottleneck features
from keras.applications import vgg16
from keras.models import Model
import keras

vgg_net = vgg16.VGG16(include_top=False, weights='imagenet',
                  input_shape=input_shape)

output = vgg_net.layers[-1].output
output = keras.layers.Flatten()(output)
vgg16_model = Model(vgg_net.input, output)
vgg16_model.trainable = False

def get_bottleneck_features(model, input_images):
  features = model.predict(input_images, verbose=0)

  return features

IMG_DIM = (150, 150)

test_folder = glob.glob('/content/drive/MyDrive/Colab Notebooks/CatsVsDogs/Small Test/Small/test/*')
test_images = [img_to_array(load_img(image, target_size=IMG_DIM)) for image in test_folder]
test_images = np.array(test_images)
test_labels = [fl.split('/')[-1].split(' ')[0].strip() for fl in test_folder]

test_images_scaled = test_images.astype('float32')
test_images_scaled /= 255
test_LE = class2num_label_transformer(test_labels)

print('Test dataset shape: ', test_images.shape)
print(test_labels[0:5], test_LE[0:5])

"""Model 1: Basic CNN Performance"""

predictions = basic_cnn.predict_classes(test_images_scaled, verbose=0)
predictions = num2class_label_transformer(predictions)
meu.display_model_performance_metrics(true_labels=test_labels, predicted_labels=predictions,
                                      classes=list(set(test_labels)))

