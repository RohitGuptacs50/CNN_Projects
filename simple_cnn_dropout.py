# -*- coding: utf-8 -*-
"""Simple_CNN_Dropout.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FZAd9HespZlnMUPv0L8GLPNbFpIJ-LBY
"""

!unzip "/content/drive/MyDrive/Colab Notebooks/CatsVsDogs/Small.zip" -d "/content/drive/MyDrive/Colab Notebooks/CatsVsDogs/Small Test"

import glob
import  numpy as np
import os
import shutil
from distutils.dir_util import copy_tree
from PIL import Image
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img

np.random.seed(42)

IMG_DIM = (150, 150)

train_folder = glob.glob('/content/drive/MyDrive/Colab Notebooks/CatsVsDogs/Small Test/Small/train/*')
train_images = [img_to_array(load_img(img, target_size = IMG_DIM)) for img in train_folder]
train_images = np.array(train_images)
train_labels = [fl.split('/')[-1].split(' ')[0].strip() for fl in train_folder]


print('Train dataset shape:', train_images.shape)

validation_folder = glob.glob('/content/drive/MyDrive/Colab Notebooks/CatsVsDogs/Small Test/Small/eval/*')
validation_images = [img_to_array(load_img(image, target_size = IMG_DIM)) for image in validation_folder]
validation_images = np.array(validation_images)
validation_labels = [fl.split('/')[-1].split(' ')[0].strip() for fl in validation_folder]

print('Validation dataset shape: ', validation_images.shape)

train_images_scaled = train_images.astype('float32')
validation_images_scaled = validation_images.astype('float32')
train_images_scaled /= 255
validation_images_scaled /= 255

print(train_images[0].shape)
array_to_img(train_images[0])

print(validation_labels[0])
print()
print(train_labels[0])

batch_size = 30
num_classes = 2
epochs = 30
input_shape = (150, 150, 3)

from sklearn.preprocessing import LabelEncoder

LE = LabelEncoder()
LE.fit(train_labels)
train_LE = LE.transform(train_labels)
validation_LE = LE.transform(validation_labels)

print(train_labels[1495:1505], train_LE[1495:1505])

#Simple CNN Model from scratch

from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from keras.models import Sequential
from keras import optimizers

model = Sequential()
model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape = input_shape))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.3))

model.add(Dense(512, activation='relu'))
model.add(Dropout(0.3))

model.add(Dense(1, activation='sigmoid'))

model.compile(loss = 'binary_crossentropy', optimizer = optimizers.RMSprop(),
              metrics=['accuracy'])

model.summary()

history = model.fit(x = train_images_scaled, y = train_LE,
                    validation_data = (validation_images_scaled, validation_LE),
                    batch_size = batch_size,
                    epochs = epochs,
                    verbose = 1)

f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
t = f.suptitle('Basic CNN Performance', fontsize = 12)
f.subplots_adjust(top = 0.901, wspace=0.35)

epoch_list = list(range(1, 31))
ax1.plot(epoch_list, history.history['accuracy'], label='Train Accuracy')
ax1.plot(epoch_list, history.history['val_accuracy'], label='Validation Accuracy')
ax1.set_xticks(np.arange(0, 31, 5))
ax1.set_ylabel('Accuracy Value')
ax1.set_xlabel('Epoch')
ax1.set_title('Accuracy')
l1 = ax1.legend(loc="best")

ax2.plot(epoch_list, history.history['loss'], label='Train Loss')
ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')
ax2.set_xticks(np.arange(0, 31, 5))
ax2.set_ylabel('Loss Value')
ax2.set_xlabel('Epoch')
ax2.set_title('Loss')
l2 = ax2.legend(loc="best")

model.save('cats_dogs_basic_cnn.h5')



